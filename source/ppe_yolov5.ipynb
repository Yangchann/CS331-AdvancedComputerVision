{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "205b62f6",
   "metadata": {
    "papermill": {
     "duration": 0.003217,
     "end_time": "2025-01-14T00:27:30.578287",
     "exception": false,
     "start_time": "2025-01-14T00:27:30.575070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Format Dataset for YOLOv5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "468271ca",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-14T00:27:30.584726Z",
     "iopub.status.busy": "2025-01-14T00:27:30.584442Z",
     "iopub.status.idle": "2025-01-14T00:32:58.403656Z",
     "shell.execute_reply": "2025-01-14T00:32:58.402712Z"
    },
    "papermill": {
     "duration": 327.824217,
     "end_time": "2025-01-14T00:32:58.405311",
     "exception": false,
     "start_time": "2025-01-14T00:27:30.581094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying train files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5183/5183 [03:30<00:00, 24.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying val files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1296/1296 [00:52<00:00, 24.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying test files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1620/1620 [01:05<00:00, 24.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the base directory containing the SH17 dataset\n",
    "base_dir = \"/kaggle/input/sh17-dataset-for-ppe-detection\"\n",
    "\n",
    "# Paths to the train and validation file lists\n",
    "train_file = os.path.join(base_dir, \"train_files.txt\")\n",
    "val_file = os.path.join(base_dir, \"val_files.txt\")\n",
    "\n",
    "# Directories for images and labels in the source dataset\n",
    "images_dir = os.path.join(base_dir, \"images\")\n",
    "labels_dir = os.path.join(base_dir, \"labels\")\n",
    "\n",
    "# Output directory for prepared data\n",
    "output_dir = \"/kaggle/working/data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Directories for train, validation, and test sets (images and labels)\n",
    "train_images_dir = os.path.join(output_dir, \"images/train\")\n",
    "val_images_dir = os.path.join(output_dir, \"images/val\")\n",
    "test_images_dir = os.path.join(output_dir, \"images/test\")\n",
    "\n",
    "train_labels_dir = os.path.join(output_dir, \"labels/train\")\n",
    "val_labels_dir = os.path.join(output_dir, \"labels/val\")\n",
    "test_labels_dir = os.path.join(output_dir, \"labels/test\")\n",
    "\n",
    "# Create all required directories if they do not exist\n",
    "for dir_path in [train_images_dir, val_images_dir, test_images_dir,\n",
    "                 train_labels_dir, val_labels_dir, test_labels_dir]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "def copy_files(file_list, dest_images_dir, dest_labels_dir):\n",
    "    \"\"\"\n",
    "    Copies image and corresponding label files to the specified directories.\n",
    "\n",
    "    Args:\n",
    "        file_list (list): List of file names to be copied.\n",
    "        dest_images_dir (str): Destination directory for images.\n",
    "        dest_labels_dir (str): Destination directory for labels.\n",
    "    \"\"\"\n",
    "    for file in tqdm(file_list):\n",
    "        file = file.strip()\n",
    "\n",
    "        # Copy the image file\n",
    "        image_path = os.path.join(images_dir, file)\n",
    "        if os.path.exists(image_path):\n",
    "            shutil.copy(image_path, dest_images_dir)\n",
    "        else:\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "\n",
    "        # Copy the corresponding label file\n",
    "        label_path = os.path.join(labels_dir, file.replace(\n",
    "            image_path.split(\".\")[-1], \"txt\"))\n",
    "        if os.path.exists(label_path):\n",
    "            shutil.copy(label_path, dest_labels_dir)\n",
    "        else:\n",
    "            print(f\"Label not found: {label_path}\")\n",
    "\n",
    "# Read the list of training files from train_files.txt\n",
    "with open(train_file, 'r') as f:\n",
    "    train_files = f.readlines()\n",
    "\n",
    "# Shuffle and split the training data into 80% training and 20% validation\n",
    "random.shuffle(train_files)\n",
    "split_idx = int(0.8 * len(train_files))\n",
    "train_split = train_files[:split_idx]\n",
    "val_split = train_files[split_idx:]\n",
    "\n",
    "# Copy the training split files\n",
    "print(\"Copying train files...\")\n",
    "copy_files(train_split, train_images_dir, train_labels_dir)\n",
    "\n",
    "# Copy the validation split files\n",
    "print(\"Copying val files...\")\n",
    "copy_files(val_split, val_images_dir, val_labels_dir)\n",
    "\n",
    "# Copy the test files listed in val_files.txt\n",
    "with open(val_file, 'r') as f:\n",
    "    test_files = f.readlines()\n",
    "\n",
    "print(\"Copying test files...\")\n",
    "copy_files(test_files, test_images_dir, test_labels_dir)\n",
    "\n",
    "print(\"Data prepared!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57f915d",
   "metadata": {
    "papermill": {
     "duration": 0.109857,
     "end_time": "2025-01-14T00:32:58.667573",
     "exception": false,
     "start_time": "2025-01-14T00:32:58.557716",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Setup environment for YOLOv5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bbb3af1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T00:32:58.891658Z",
     "iopub.status.busy": "2025-01-14T00:32:58.891369Z",
     "iopub.status.idle": "2025-01-14T00:33:00.894808Z",
     "shell.execute_reply": "2025-01-14T00:33:00.893919Z"
    },
    "papermill": {
     "duration": 2.11699,
     "end_time": "2025-01-14T00:33:00.896320",
     "exception": false,
     "start_time": "2025-01-14T00:32:58.779330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\r\n",
      "remote: Enumerating objects: 17129, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (49/49), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (39/39), done.\u001b[K\r\n",
      "remote: Total 17129 (delta 32), reused 10 (delta 10), pack-reused 17080 (from 4)\u001b[K\r\n",
      "Receiving objects: 100% (17129/17129), 15.84 MiB | 31.55 MiB/s, done.\r\n",
      "Resolving deltas: 100% (11744/11744), done.\r\n",
      "/kaggle/working/yolov5\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5.git\n",
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "774251d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T00:33:01.124440Z",
     "iopub.status.busy": "2025-01-14T00:33:01.124121Z",
     "iopub.status.idle": "2025-01-14T00:33:13.579948Z",
     "shell.execute_reply": "2025-01-14T00:33:13.578699Z"
    },
    "papermill": {
     "duration": 12.572863,
     "end_time": "2025-01-14T00:33:13.581644",
     "exception": false,
     "start_time": "2025-01-14T00:33:01.008781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.1.43)\r\n",
      "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\r\n",
      "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.26.4)\r\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.10.0.84)\r\n",
      "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (10.4.0)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\r\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.32.3)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.13.1)\r\n",
      "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\r\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.4.1+cu121)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.19.1+cu121)\r\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.5)\r\n",
      "Collecting ultralytics>=8.2.34 (from -r requirements.txt (line 18))\r\n",
      "  Downloading ultralytics-8.3.61-py3-none-any.whl.metadata (35 kB)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (2.1.4)\r\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.12.2)\r\n",
      "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (71.0.4)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.11)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.53.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (24.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2024.8.30)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.16.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2024.6.1)\r\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (9.0.0)\r\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics>=8.2.34->-r requirements.txt (line 18))\r\n",
      "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.1)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\r\n",
      "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\r\n",
      "Downloading ultralytics-8.3.61-py3-none-any.whl (906 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.9/906.9 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\r\n",
      "Installing collected packages: ultralytics-thop, thop, ultralytics\r\n",
      "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.3.61 ultralytics-thop-2.0.13\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m710.6/710.6 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m980.3/980.3 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install -q comet_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9c5440",
   "metadata": {
    "papermill": {
     "duration": 0.11395,
     "end_time": "2025-01-14T00:33:13.810125",
     "exception": false,
     "start_time": "2025-01-14T00:33:13.696175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Create YAML file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daeee42a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T00:33:14.043230Z",
     "iopub.status.busy": "2025-01-14T00:33:14.042733Z",
     "iopub.status.idle": "2025-01-14T00:33:14.146501Z",
     "shell.execute_reply": "2025-01-14T00:33:14.145335Z"
    },
    "papermill": {
     "duration": 0.225331,
     "end_time": "2025-01-14T00:33:14.148026",
     "exception": false,
     "start_time": "2025-01-14T00:33:13.922695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML file has been created: ../yolo.yaml\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# Define the data to be written into the YAML file\n",
    "data = {\n",
    "    \"names\": [\n",
    "        \"Person\", \"Ear\", \"Earmuffs\", \"Face\", \"Face-guard\", \"Face-mask-medical\",\n",
    "        \"Foot\", \"Tools\", \"Glasses\", \"Gloves\", \"Helmet\", \"Hands\", \"Head\",\n",
    "        \"Medical-suit\", \"Shoes\", \"Safety-suit\", \"Safety-vest\"\n",
    "    ],  \n",
    "    \"nc\": 17,  \n",
    "    \"test\": \"/kaggle/working/data/images/test\",  \n",
    "    \"train\": \"/kaggle/working/data/images/train\", \n",
    "    \"val\": \"/kaggle/working/data/images/val\"\n",
    "}\n",
    "\n",
    "# Define the output path for the YAML file\n",
    "yaml_file_path = \"../yolo.yaml\"\n",
    "\n",
    "# Write the data to the YAML file\n",
    "with open(yaml_file_path, \"w\") as yaml_file:\n",
    "    yaml.dump(data, yaml_file, default_flow_style=False)\n",
    "\n",
    "print(f\"YAML file has been created: {yaml_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6d1abc",
   "metadata": {
    "papermill": {
     "duration": 0.121175,
     "end_time": "2025-01-14T00:33:14.387508",
     "exception": false,
     "start_time": "2025-01-14T00:33:14.266333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Update AMP Autocast Syntax in train.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b9f2c0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T00:33:14.665463Z",
     "iopub.status.busy": "2025-01-14T00:33:14.664934Z",
     "iopub.status.idle": "2025-01-14T00:33:14.701793Z",
     "shell.execute_reply": "2025-01-14T00:33:14.700878Z"
    },
    "papermill": {
     "duration": 0.198004,
     "end_time": "2025-01-14T00:33:14.703616",
     "exception": false,
     "start_time": "2025-01-14T00:33:14.505612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The deprecated `torch.cuda.amp.autocast` warnings in train.py have been updated!\n"
     ]
    }
   ],
   "source": [
    "# Define the file path for the script to be updated\n",
    "file_path = \"/kaggle/working/yolov5/train.py\"\n",
    "\n",
    "# Read the content of the file line by line\n",
    "with open(file_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Initialize a list to store updated lines\n",
    "updated_lines = []\n",
    "\n",
    "# Iterate through each line and update specific syntax\n",
    "for line in lines:\n",
    "    if \"with torch.cuda.amp.autocast(amp):\" in line:\n",
    "        # Replace the deprecated torch.cuda.amp.autocast syntax with the new syntax\n",
    "        line = line.replace(\n",
    "            \"with torch.cuda.amp.autocast(amp):\",\n",
    "            \"with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\"\n",
    "        )\n",
    "    # Add the updated line to the list\n",
    "    updated_lines.append(line)\n",
    "\n",
    "# Write the modified content back to the file\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.writelines(updated_lines)\n",
    "\n",
    "# Notify the user that the updates have been applied\n",
    "print(\"The deprecated `torch.cuda.amp.autocast` warnings in train.py have been updated!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124d79a1",
   "metadata": {
    "papermill": {
     "duration": 0.12367,
     "end_time": "2025-01-14T00:33:15.001153",
     "exception": false,
     "start_time": "2025-01-14T00:33:14.877483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Train model YOLOv5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1121a983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T00:33:15.270934Z",
     "iopub.status.busy": "2025-01-14T00:33:15.270568Z",
     "iopub.status.idle": "2025-01-14T06:44:32.406751Z",
     "shell.execute_reply": "2025-01-14T06:44:32.405735Z"
    },
    "papermill": {
     "duration": 22277.262866,
     "end_time": "2025-01-14T06:44:32.409436",
     "exception": false,
     "start_time": "2025-01-14T00:33:15.146570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \r\n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\r\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\r\n",
      "2025-01-14 00:33:28.680985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-01-14 00:33:28.871572: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2025-01-14 00:33:28.925470: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=, data=../yolo.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/kaggle/working/results/yolov5/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\r\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\r\n",
      "YOLOv5 🚀 v7.0-395-g6420a1db Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\r\n",
      "\r\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\r\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /kaggle/working/results/yolov5/train', view at http://localhost:6006/\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Using '/kaggle/working/yolov5/.cometml-runs' path as offline directory. Pass 'offline_directory' parameter into constructor or set the 'COMET_OFFLINE_DIRECTORY' environment variable to manually choose where to store offline experiment archives.\r\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\r\n",
      "100%|████████████████████████████████████████| 755k/755k [00:00<00:00, 49.7MB/s]\r\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt to yolov5m.pt...\r\n",
      "100%|██████████████████████████████████████| 40.8M/40.8M [00:00<00:00, 94.7MB/s]\r\n",
      "\r\n",
      "Overriding model.yaml nc=80 with nc=17\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \r\n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \r\n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \r\n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \r\n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \r\n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \r\n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \r\n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \r\n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \r\n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \r\n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \r\n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \r\n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \r\n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \r\n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \r\n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \r\n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \r\n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \r\n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \r\n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \r\n",
      " 24      [17, 20, 23]  1     88902  models.yolo.Detect                      [17, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\r\n",
      "Model summary: 291 layers, 20935974 parameters, 20935974 gradients, 48.4 GFLOPs\r\n",
      "\r\n",
      "Transferred 475/481 items from yolov5m.pt\r\n",
      "/kaggle/working/yolov5/models/common.py:895: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\r\n",
      "  with amp.autocast(autocast):\r\n",
      "/kaggle/working/yolov5/models/common.py:895: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\r\n",
      "  with amp.autocast(autocast):\r\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\r\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\r\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\r\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\r\n",
      "  self.pid = os.fork()\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/data/labels/train... 5183 images, 0 backgrounds,\u001b[0m\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/data/labels/train.cache\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/data/labels/val... 1296 images, 0 backgrounds, 0 c\u001b[0m\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/data/labels/val.cache\r\n",
      "\r\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.65 anchors/target, 0.987 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\r\n",
      "Plotting labels to /kaggle/working/results/yolov5/train/exp/labels.jpg... \r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/usr/local/lib/python3.10/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/kaggle/working/yolov5/train.py:355: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\r\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=amp)\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 4 dataloader workers\r\n",
      "Logging results to \u001b[1m/kaggle/working/results/yolov5/train/exp\u001b[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "        0/9      7.32G    0.08213    0.07893    0.05428        192        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all       1296      12518      0.824      0.179      0.164       0.07\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "        1/9      7.32G    0.06143    0.06714    0.03302        239        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all       1296      12518      0.832      0.223      0.226      0.111\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "        2/9      7.32G    0.05649    0.06525    0.02717        202        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all       1296      12518      0.841      0.279      0.302      0.161\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "        3/9      7.34G    0.05064    0.06479    0.02408        174        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all       1296      12518      0.873       0.29      0.326       0.18\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "        4/9      7.34G    0.04783    0.06286    0.02238        257        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all       1296      12518      0.871      0.305      0.356      0.197\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "        5/9      7.34G     0.0448     0.0617      0.021        326        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all       1296      12518       0.83      0.319      0.368      0.211\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "        6/9      7.34G    0.04331     0.0605    0.01999        164        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all       1296      12518      0.832      0.337       0.39      0.228\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "        7/9      7.34G    0.04147     0.0589    0.01887        249        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all       1296      12518      0.825      0.346      0.405      0.238\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "        8/9      7.34G    0.04022    0.05827    0.01817        341        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all       1296      12518      0.765      0.384       0.43      0.256\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "        9/9      7.34G    0.03887    0.05665    0.01729        245        640: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all       1296      12518      0.789      0.386      0.441      0.265\r\n",
      "\r\n",
      "10 epochs completed in 6.106 hours.\r\n",
      "Optimizer stripped from /kaggle/working/results/yolov5/train/exp/weights/last.pt, 42.3MB\r\n",
      "Optimizer stripped from /kaggle/working/results/yolov5/train/exp/weights/best.pt, 42.3MB\r\n",
      "\r\n",
      "Validating /kaggle/working/results/yolov5/train/exp/weights/best.pt...\r\n",
      "Fusing layers... \r\n",
      "Model summary: 212 layers, 20917590 parameters, 0 gradients, 48.1 GFLOPs\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all       1296      12518      0.787      0.386      0.441      0.265\r\n",
      "                Person       1296       2322      0.901       0.86      0.901      0.685\r\n",
      "                   Ear       1296       1251       0.83      0.773      0.781      0.433\r\n",
      "              Earmuffs       1296         63          1          0     0.0543     0.0372\r\n",
      "                  Face       1296       1460      0.815      0.823      0.858      0.571\r\n",
      "            Face-guard       1296         29          1          0     0.0411     0.0222\r\n",
      "     Face-mask-medical       1296        113      0.854      0.258       0.48      0.253\r\n",
      "                  Foot       1296        111          1          0     0.0932     0.0422\r\n",
      "                 Tools       1296        822      0.455      0.313      0.304      0.143\r\n",
      "               Glasses       1296        320      0.496      0.312      0.331      0.116\r\n",
      "                Gloves       1296        494      0.701      0.526      0.584      0.323\r\n",
      "                Helmet       1296        168      0.602      0.387      0.404      0.225\r\n",
      "                 Hands       1296       2520      0.836      0.806      0.847      0.541\r\n",
      "                  Head       1296       2022       0.89      0.829      0.863      0.614\r\n",
      "          Medical-suit       1296         25          1          0      0.123     0.0693\r\n",
      "                 Shoes       1296        684      0.721      0.582      0.602      0.317\r\n",
      "           Safety-suit       1296         35          1          0     0.0822     0.0426\r\n",
      "           Safety-vest       1296         79      0.283     0.0886      0.154     0.0771\r\n",
      "Results saved to \u001b[1m/kaggle/working/results/yolov5/train/exp\u001b[0m\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml OfflineExperiment Summary\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : exp\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : [OfflineExperiment will get URL after upload]\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [323]                : (1.5549466609954834, 4.496941089630127)\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP_0.5 [20]      : (0.16399120339545856, 0.4413892300203739)\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP_0.5:0.95 [20] : (0.06999425578298214, 0.2653896890735504)\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision [20]    : (0.7650076212639905, 0.8732695817386396)\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall [20]       : (0.1793943767456831, 0.38550055947125283)\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [20]       : (0.0388677716255188, 0.08212760090827942)\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [20]       : (0.0172869972884655, 0.05428249016404152)\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/obj_loss [20]       : (0.05665317177772522, 0.07892833650112152)\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [20]         : (0.038232527673244476, 0.060771360993385315)\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [20]         : (0.01637411303818226, 0.03758570924401283)\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/obj_loss [20]         : (0.047711629420518875, 0.05402132496237755)\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     x/lr0 [20]                : (0.00208, 0.0700925925925926)\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     x/lr1 [20]                : (0.00208, 0.008011748971193416)\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     x/lr2 [20]                : (0.00208, 0.008011748971193416)\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name                        : exp\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_log_batch_metrics     : False\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_log_confusion_matrix  : True\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_log_per_class_metrics : False\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_max_image_uploads     : 100\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_mode                  : online\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_model_name            : yolov5\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hasNestedParams             : True\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     offline_experiment          : True\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     anchor_t            : 4.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     artifact_alias      : latest\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size          : 16\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bbox_interval       : -1\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box                 : 0.05\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bucket              : \r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cache               : None\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg                 : \r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls                 : 0.10625\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls_pw              : 1.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste          : 0.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr              : False\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees             : 0.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device              : \r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     entity              : None\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     evolve              : None\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     evolve_population   : data/hyps\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok            : False\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fl_gamma            : 0.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr              : 0.5\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud              : 0.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze              : [0]\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h               : 0.015\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s               : 0.7\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v               : 0.4\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|anchor_t        : 4.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|box             : 0.05\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|cls             : 0.5\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|cls_pw          : 1.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|copy_paste      : 0.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|degrees         : 0.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|fl_gamma        : 0.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|fliplr          : 0.5\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|flipud          : 0.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|hsv_h           : 0.015\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|hsv_s           : 0.7\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|hsv_v           : 0.4\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|iou_t           : 0.2\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|lr0             : 0.01\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|lrf             : 0.01\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|mixup           : 0.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|momentum        : 0.937\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|mosaic          : 1.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|obj             : 1.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|obj_pw          : 1.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|perspective     : 0.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|scale           : 0.5\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|shear           : 0.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|translate       : 0.1\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|warmup_bias_lr  : 0.1\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|warmup_epochs   : 3.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|warmup_momentum : 0.8\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|weight_decay    : 0.0005\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     image_weights       : False\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz               : 640\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou_t               : 0.2\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_smoothing     : 0.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     local_rank          : -1\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0                 : 0.01\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf                 : 0.01\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup               : 0.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum            : 0.937\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic              : 1.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale         : False\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                : exp\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     ndjson_console      : False\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     ndjson_file         : False\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     noautoanchor        : False\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     noplots             : False\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nosave              : False\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     noval               : False\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     obj                 : 1.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     obj_pw              : 1.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer           : SGD\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience            : 100\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective         : 0.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     quad                : False\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect                : False\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume              : False\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume_evolve       : None\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir            : /kaggle/working/results/yolov5/train/exp\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period         : -1\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale               : 0.5\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed                : 0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear               : 0.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls          : False\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     sync_bn             : False\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate           : 0.1\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     upload_dataset      : False\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_conf_threshold  : 0.001\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_iou_threshold   : 0.6\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr      : 0.1\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs       : 3.0\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum     : 0.8\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay        : 0.0005\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers             : 8\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     asset               : 13 (2.78 MB)\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata        : 1\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 106\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still saving offline stats to messages file before program termination (may take up to 120 seconds)\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Begin archiving the offline data.\r\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m To upload this offline experiment, run:\r\n",
      "    comet upload /kaggle/working/yolov5/.cometml-runs/d04ad021ce3b4955b404360a5d9fc709.zip\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 640 --epochs 10 --batch-size 16 --data ../yolo.yaml --weights yolov5m.pt --project /kaggle/working/results/yolov5/train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895f3e29",
   "metadata": {
    "papermill": {
     "duration": 0.403582,
     "end_time": "2025-01-14T06:44:33.118849",
     "exception": false,
     "start_time": "2025-01-14T06:44:32.715267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Evaluate on validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "091121c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T06:44:33.731813Z",
     "iopub.status.busy": "2025-01-14T06:44:33.731490Z",
     "iopub.status.idle": "2025-01-14T06:47:58.477312Z",
     "shell.execute_reply": "2025-01-14T06:47:58.476125Z"
    },
    "papermill": {
     "duration": 205.054317,
     "end_time": "2025-01-14T06:47:58.478919",
     "exception": false,
     "start_time": "2025-01-14T06:44:33.424602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=../yolo.yaml, weights=['/kaggle/working/results/yolov5/train/exp/weights/best.pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=/kaggle/working/results/yolov5/val, name=exp, exist_ok=False, half=False, dnn=False\r\n",
      "YOLOv5 🚀 v7.0-395-g6420a1db Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\r\n",
      "\r\n",
      "Fusing layers... \r\n",
      "Model summary: 212 layers, 20917590 parameters, 0 gradients, 48.1 GFLOPs\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/data/labels/val.cache... 1296 images, 0 background\u001b[0m\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all       1296      12518      0.787      0.386      0.441      0.266\r\n",
      "                Person       1296       2322      0.897       0.86        0.9      0.685\r\n",
      "                   Ear       1296       1251      0.825       0.77      0.778      0.433\r\n",
      "              Earmuffs       1296         63          1          0     0.0543     0.0399\r\n",
      "                  Face       1296       1460       0.81      0.823      0.857      0.572\r\n",
      "            Face-guard       1296         29          1          0     0.0415     0.0224\r\n",
      "     Face-mask-medical       1296        113      0.854       0.26       0.48      0.254\r\n",
      "                  Foot       1296        111          1          0     0.0938     0.0424\r\n",
      "                 Tools       1296        822      0.456      0.316      0.304      0.143\r\n",
      "               Glasses       1296        320      0.496      0.316      0.334      0.117\r\n",
      "                Gloves       1296        494      0.703      0.526      0.584      0.324\r\n",
      "                Helmet       1296        168      0.609       0.39      0.404      0.225\r\n",
      "                 Hands       1296       2520      0.834      0.805      0.847      0.541\r\n",
      "                  Head       1296       2022      0.891      0.829      0.863      0.614\r\n",
      "          Medical-suit       1296         25          1          0      0.123     0.0693\r\n",
      "                 Shoes       1296        684      0.721      0.582      0.602      0.319\r\n",
      "           Safety-suit       1296         35          1          0     0.0812     0.0413\r\n",
      "           Safety-vest       1296         79      0.281     0.0886      0.153     0.0774\r\n",
      "Speed: 0.1ms pre-process, 5.6ms inference, 3.3ms NMS per image at shape (16, 3, 640, 640)\r\n",
      "Results saved to \u001b[1m/kaggle/working/results/yolov5/val/exp\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python val.py --weights /kaggle/working/results/yolov5/train/exp/weights/best.pt \\\n",
    "               --data ../yolo.yaml \\\n",
    "               --img 640 \\\n",
    "               --batch-size 16 \\\n",
    "               --project /kaggle/working/results/yolov5/val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffed8ff",
   "metadata": {
    "papermill": {
     "duration": 0.309138,
     "end_time": "2025-01-14T06:47:59.171138",
     "exception": false,
     "start_time": "2025-01-14T06:47:58.862000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Evaluate on test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39ead415",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T06:47:59.787399Z",
     "iopub.status.busy": "2025-01-14T06:47:59.787084Z",
     "iopub.status.idle": "2025-01-14T06:52:12.581462Z",
     "shell.execute_reply": "2025-01-14T06:52:12.580499Z"
    },
    "papermill": {
     "duration": 253.10415,
     "end_time": "2025-01-14T06:52:12.583092",
     "exception": false,
     "start_time": "2025-01-14T06:47:59.478942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=../yolo.yaml, weights=['/kaggle/working/results/yolov5/train/exp/weights/best.pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=test, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=/kaggle/working/results/yolov5/test, name=exp, exist_ok=False, half=False, dnn=False\r\n",
      "YOLOv5 🚀 v7.0-395-g6420a1db Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\r\n",
      "\r\n",
      "Fusing layers... \r\n",
      "Model summary: 212 layers, 20917590 parameters, 0 gradients, 48.1 GFLOPs\r\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning /kaggle/working/data/labels/test... 1620 images, 0 backgrounds, 0\u001b[0m\r\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /kaggle/working/data/labels/test.cache\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all       1620      15358      0.795      0.426      0.466      0.282\r\n",
      "                Person       1620       2734      0.879      0.883      0.914      0.705\r\n",
      "                   Ear       1620       1612      0.816      0.743      0.761      0.429\r\n",
      "              Earmuffs       1620         49          1          0     0.0233     0.0118\r\n",
      "                  Face       1620       1855      0.811      0.852      0.888      0.605\r\n",
      "            Face-guard       1620         24          1          0     0.0444     0.0187\r\n",
      "     Face-mask-medical       1620        151      0.818      0.208      0.401      0.212\r\n",
      "                  Foot       1620        149          1          0     0.0585      0.019\r\n",
      "                 Tools       1620        923      0.462      0.363      0.346      0.166\r\n",
      "               Glasses       1620        398      0.464      0.337      0.306      0.105\r\n",
      "                Gloves       1620        529      0.666      0.546      0.583      0.335\r\n",
      "                Helmet       1620        154      0.625      0.671      0.652      0.381\r\n",
      "                 Hands       1620       3212      0.848      0.822      0.863       0.55\r\n",
      "                  Head       1620       2427      0.877      0.881      0.909      0.646\r\n",
      "          Medical-suit       1620         43          1          0      0.138     0.0809\r\n",
      "                 Shoes       1620        956      0.717      0.591      0.645      0.346\r\n",
      "           Safety-suit       1620         45          1          0     0.0835     0.0392\r\n",
      "           Safety-vest       1620         97      0.532       0.34      0.304      0.152\r\n",
      "Speed: 0.1ms pre-process, 5.9ms inference, 3.3ms NMS per image at shape (16, 3, 640, 640)\r\n",
      "Results saved to \u001b[1m/kaggle/working/results/yolov5/test/exp\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python val.py --weights /kaggle/working/results/yolov5/train/exp/weights/best.pt \\\n",
    "               --data ../yolo.yaml \\\n",
    "               --img 640 \\\n",
    "               --batch-size 16 \\\n",
    "               --task test \\\n",
    "               --project /kaggle/working/results/yolov5/test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ef26d1",
   "metadata": {
    "papermill": {
     "duration": 0.316356,
     "end_time": "2025-01-14T06:52:13.212553",
     "exception": false,
     "start_time": "2025-01-14T06:52:12.896197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Zip result folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5621b54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T06:52:13.839756Z",
     "iopub.status.busy": "2025-01-14T06:52:13.839442Z",
     "iopub.status.idle": "2025-01-14T06:52:18.532815Z",
     "shell.execute_reply": "2025-01-14T06:52:18.531790Z"
    },
    "papermill": {
     "duration": 5.009367,
     "end_time": "2025-01-14T06:52:18.534416",
     "exception": false,
     "start_time": "2025-01-14T06:52:13.525049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder /kaggle/working/results has been compressed into /kaggle/working/results.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "def zip_folder(folder_path, output_zip_path):\n",
    "    \"\"\"\n",
    "    Compress an entire folder into a .zip file.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder to be compressed.\n",
    "        output_zip_path (str): Path to save the resulting zip file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a new zip file with write mode and compression\n",
    "        with zipfile.ZipFile(output_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            # Traverse through all files in the folder\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                for file in files:\n",
    "                    # Get the full path of the current file\n",
    "                    full_path = os.path.join(root, file)\n",
    "                    # Calculate the relative path for the zip file\n",
    "                    relative_path = os.path.relpath(full_path, folder_path)\n",
    "                    # Add the file to the zip archive with its relative path\n",
    "                    zipf.write(full_path, relative_path)\n",
    "        print(f\"Folder {folder_path} has been compressed into {output_zip_path}\")\n",
    "    except Exception as e:\n",
    "        # Catch any exceptions and print an error message\n",
    "        print(f\"Error while compressing the folder: {e}\")\n",
    "\n",
    "# Use the function to compress a folder\n",
    "results_folder = \"/kaggle/working/results\"  # Path to the folder to compress\n",
    "output_zip = \"/kaggle/working/results.zip\"  # Path for the output zip file\n",
    "zip_folder(results_folder, output_zip)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5329058,
     "sourceId": 8853182,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23090.826513,
   "end_time": "2025-01-14T06:52:19.191754",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-14T00:27:28.365241",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
